{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a8e7824826c0f8a3fce51bce528184dc2e213888"
   },
   "source": [
    "# Exercises\n",
    "\n",
    "## Set Up\n",
    "\n",
    "Today you will create partial dependence plots and practice building insights with data from the [Taxi Fare Prediction](https://www.kaggle.com/c/new-york-city-taxi-fare-prediction) competition.\n",
    "\n",
    "We have again provided code to do the basic loading, review and model-building. Run the cell below to set everything up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "36938c9eeafa48cfa4778006c77921ef1c8bdcac"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Data manipulation code below here\n",
    "data = pd.read_csv('../NY_City_Taxi_Fare_Prediction/train.csv', nrows=50000)\n",
    "\n",
    "# Remove data with extreme outlier coordinates or negative fares\n",
    "data = data.query('pickup_latitude > 40.7 and pickup_latitude < 40.8 and ' +\n",
    "                  'dropoff_latitude > 40.7 and dropoff_latitude < 40.8 and ' +\n",
    "                  'pickup_longitude > -74 and pickup_longitude < -73.9 and ' +\n",
    "                  'dropoff_longitude > -74 and dropoff_longitude < -73.9 and ' +\n",
    "                  'fare_amount > 0'\n",
    "                  )\n",
    "\n",
    "y = data.fare_amount\n",
    "\n",
    "base_features = ['pickup_longitude',\n",
    "                 'pickup_latitude',\n",
    "                 'dropoff_longitude',\n",
    "                 'dropoff_latitude']\n",
    "\n",
    "X = data[base_features]\n",
    "print(X[:5])\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "first_model = RandomForestRegressor(n_estimators=30, random_state=1).fit(train_X, train_y)\n",
    "print(\"Data sample:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4459e5e67e9af94327f81a2624136c40df08ec90"
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "232c25399b529406ba96e6fdbf69e033d510a9f6"
   },
   "source": [
    "## Question 1\n",
    "\n",
    "Here is the code to plot the partial dependence plot for pickup_longitude.  Run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5d7ae796880524531e328a0408c42fc60e1d753f"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from pdpbox import pdp, get_dataset, info_plots\n",
    "\n",
    "feat_name = 'pickup_longitude'\n",
    "pdp_dist = pdp.pdp_isolate(model=first_model, dataset=val_X, model_features=base_features, feature=feat_name)\n",
    "\n",
    "pdp.pdp_plot(pdp_dist, feat_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "849e31523bd7c09746b9181c1f8b165844aea195"
   },
   "source": [
    "Why does the partial dependence plot have this U-shape?\n",
    "\n",
    "Does your explanation suggest what shape to expect in the partial dependence plots for the other features?\n",
    "\n",
    "Create all other partial plots in a for-loop below (copying the appropriate lines from the code above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e4a41738f76a91406bba0bbb142af2774c06b280"
   },
   "outputs": [],
   "source": [
    "for feat_name in base_features:\n",
    "    pdp_dist = pdp.pdp_isolate(model=first_model, dataset=val_X, model_features=base_features, feature=feat_name)\n",
    "    pdp.pdp_plot(pdp_dist, feat_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "84d6d6174b5fb9fd0cbc761ccf99c579489cc82c"
   },
   "source": [
    "Do the shapes match your expectations for what shapes they would have? Can you explain the shape now that you've seen them? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "19f6a163074796f60dcc8a6233c61b942efff9ce"
   },
   "source": [
    "Solution : \n",
    "We have a sense from the permutation importance results that distance is the most important determinant of taxi fare.\n",
    "\n",
    "This model didn't include distance measures (like absolute change in latitude or longitude) as features, so coordinate features (like pickup_longitude) capture the effect of distance. Being picked up near the center of the longitude values lowers predicted fares on average, because it means shorter trips (on average).\n",
    "\n",
    "For the same reason, we see the general U-shape in all our partial dependence plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "287479c6dbe296a457016dd31800c05ff9ecab4d"
   },
   "source": [
    "## Q2\n",
    "\n",
    "Now you will run a 2D partial dependence plot.  As a reminder, here is the code from the tutorial.  \n",
    "\n",
    "```\n",
    "inter1  =  pdp.pdp_interact(model=my_model, dataset=val_X, model_features=feature_names, features=['Goal Scored', 'Distance Covered (Kms)'])\n",
    "\n",
    "pdp.pdp_interact_plot(pdp_interact_out=inter1, feature_names=['Goal Scored', 'Distance Covered (Kms)'], plot_type='contour')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Create a 2D plot for the features `pickup_longitude` and `dropoff_longitude`.  Plot it appropriately?\n",
    "\n",
    "What do you expect it to look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dbdf39c5c7b967168553c4257cdaaa731e40b69d"
   },
   "outputs": [],
   "source": [
    "# Add your code here\n",
    "\n",
    "inter2  =  pdp.pdp_interact(model=first_model, dataset=val_X, model_features=base_features, features=['pickup_longitude', 'dropoff_longitude'])\n",
    "\n",
    "pdp.pdp_interact_plot(pdp_interact_out=inter2, feature_names=['pickup_longitude', 'dropoff_longitude'], plot_type='contour')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c510657a0a7afc607b0347318f9e5e2054d3174f"
   },
   "source": [
    "Solution: \n",
    "You should expect the plot to have contours running along a diagonal. We see that to some extent, though there are interesting caveats.\n",
    "\n",
    "We expect the diagonal contours because these are pairs of values where the pickup and dropoff longitudes are nearby, indicating shorter trips (controlling for other factors).\n",
    "\n",
    "As you get further from the central diagonal, we should expect prices to increase as the distances between the pickup and dropoff longitudes also increase.\n",
    "\n",
    "The surprising feature is that prices increase as you go further to the upper-right of this graph, even staying near that 45-degree line.\n",
    "\n",
    "This could be worth further investigation, though the effect of moving to the upper right of this graph is small compared to moving away from that 45-degree line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9fe44ea4877d7bdba13de6f73b8f6207352b0c24"
   },
   "source": [
    "## Question 3\n",
    "Consider a ride starting at longitude -73.92 and ending at longitude -74. Using the graph from the last question, estimate how much money the rider would have saved if they'd started the ride at longitude -73.98 instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cb053f46235d6a2ce1be9a8db5e9d7e09fdfa1ac"
   },
   "outputs": [],
   "source": [
    "savings_from_shorter_trip = 15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "101cf11010bf879d035ca57576e49041ebeb2c35"
   },
   "source": [
    "For a solution or hint, uncomment the appropriate line below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "06165d10822ff223946c1a48f0b3be1b9fda7e62"
   },
   "source": [
    "Hint: \n",
    "First find the vertical level corresponding to -74 dropoff longitude. Then read off the horizontal values you are switching between. Use the white contour lines to orient yourself on what values you are near. You can round to the nearest integer rather than stressing about the exact cost to the nearest penny\n",
    "\n",
    "Solution: \n",
    "About $15. The price decreases from slightly more than $24 to slightly more than $9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "186d079773ded31167d45d739f58db2be8a660a2"
   },
   "source": [
    "## Question 4\n",
    "In the PDP's you've seen so far, location features have primarily served as a proxy to capture distance traveled. In the permutation importance lessons, you added the features `abs_lon_change` and `abs_lat_change` as a more direct measure of distance.\n",
    "\n",
    "Create these features again here. You only need to fill in the top two lines.  Then run the following cell.  \n",
    "\n",
    "**After you run it, identify the most important difference between this partial dependence plot and the one you got without absolute value features. The code to generate the PDP without absolute value features is at the top of this code cell.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a93a353f40d54f21476502c49ccc4b89c1ef3f2"
   },
   "outputs": [],
   "source": [
    "# This is the PDP for pickup_longitude without the absolute difference features. Included here to help compare it to the new PDP you create\n",
    "feat_name = 'pickup_longitude'\n",
    "pdp_dist_original = pdp.pdp_isolate(model=first_model, dataset=val_X, model_features=base_features, feature=feat_name)\n",
    "\n",
    "pdp.pdp_plot(pdp_dist_original, feat_name)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# create new features\n",
    "data['abs_lon_change'] = abs(data.dropoff_longitude - data.pickup_longitude)\n",
    "data['abs_lat_change'] = abs(data.dropoff_longitude - data.pickup_longitude)\n",
    "\n",
    "features_2  = ['pickup_longitude',\n",
    "               'pickup_latitude',\n",
    "               'dropoff_longitude',\n",
    "               'dropoff_latitude',\n",
    "               'abs_lat_change',\n",
    "               'abs_lon_change']\n",
    "\n",
    "X = data[features_2]\n",
    "new_train_X, new_val_X, new_train_y, new_val_y = train_test_split(X, y, random_state=1)\n",
    "second_model = RandomForestRegressor(n_estimators=30, random_state=1).fit(new_train_X, new_train_y)\n",
    "\n",
    "feat_name = 'pickup_longitude'\n",
    "pdp_dist = pdp.pdp_isolate(model=second_model, dataset=new_val_X, model_features=features_2, feature=feat_name)\n",
    "\n",
    "pdp.pdp_plot(pdp_dist, feat_name)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1f6194ed97909a058f667bfecb2725154546d600"
   },
   "source": [
    "The biggest difference is that the partial dependence plot became much smaller. The the lowest vertical value is about 15 below the highest vertical value in the top chart,whereas this difference is only about 15 below the highest vertical value in the top chart, whereas this difference is only about 3 in the chart you just created. In other words, once you control for absolute distance traveled, the pickup_longitude has only a very small impact on predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "92163c49b44c800d216f85a29a720a226bae5a82"
   },
   "source": [
    "## Question 5\n",
    "Consider a scenario where you have only 2 predictive features, which we will call `feat_A` and `feat_B`. Both features have minimum values of -1 and maximum values of 1.  The partial dependence plot for `feat_A` increases steeply over its whole range, whereas the partial dependence plot for feature B increases at a slower rate (less steeply) over its whole range.\n",
    "\n",
    "Does this guarantee that `feat_A` will have a higher permutation importance than `feat_B`.  Why or why not?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "288c0816df1d284101eac96d54490c556dea2b46"
   },
   "source": [
    "Solution: \n",
    "No. This doesn't guarantee feat_a is more important. For example, feat_a could have a big effect in the cases where it varies, but could have a single value 99\\% of the time. In that case, permuting feat_a wouldn't matter much, since most values would be unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6c8aff7d38054b50afadbd8723ae81a6c1d4ff93"
   },
   "source": [
    "## Q6\n",
    "The code cell below does the following:\n",
    "\n",
    "1. Creates two features, `X1` and `X2`, having random values in the range [-2, 2].\n",
    "2. Creates a target variable `y`, which is always 1.\n",
    "3. Trains a `RandomForestRegressor` model to predict `y` given `X1` and `X2`.\n",
    "4. Creates a PDP plot for `X1` and a scatter plot of `X1` vs. `y`.\n",
    "\n",
    "Do you have a prediction about what the PDP plot will look like? Run the cell to find out.\n",
    "\n",
    "Modify the initialization of `y` so that our PDP plot has a positive slope in the range [-1,1], and a negative slope everywhere else. (Note: *you should only modify the creation of `y`, leaving `X1`, `X2`, and `my_model` unchanged.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cd048ef91677dac48658d765ef22e483c9d19287"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import rand\n",
    "\n",
    "\n",
    "n_samples = 20000\n",
    "\n",
    "# Create array holding predictive feature\n",
    "X1 = 4 * rand(n_samples) - 2\n",
    "X2 = 4 * rand(n_samples) - 2\n",
    "\n",
    "# Create y. you should have X1 and X2 in the expression for y\n",
    "#y = np.ones(n_samples)\n",
    "y = -2 * X1 * (X1<-1) + X1 - 2 * X1 * (X1>1) - X2\n",
    "# create dataframe because pdp_isolate expects a dataFrame as an argument\n",
    "my_df = pd.DataFrame({'X1': X1, 'X2': X2, 'y': y})\n",
    "predictors_df = my_df.drop(['y'], axis=1)\n",
    "\n",
    "my_model = RandomForestRegressor(n_estimators=30, random_state=1).fit(predictors_df, my_df.y)\n",
    "\n",
    "pdp_dist = pdp.pdp_isolate(model=my_model, dataset=my_df, model_features=['X1', 'X2'], feature='X1')\n",
    "\n",
    "# visualize your results\n",
    "pdp.pdp_plot(pdp_dist, 'X1')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ef198c10faa79837686d4daebc4daf864cd9a16d"
   },
   "source": [
    "## Question 7\n",
    "Create a dataset with 2 features and a target, such that the pdp of the first feature is flat, but its permutation importance is high.  We will use a RandomForest for the model.\n",
    "\n",
    "*Note: You only need to supply the lines that create the variables X1, X2 and y. The code to build the model and calculate insights is provided*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "371abd322b06274adb7cd0d2f59d96429e6a97ca"
   },
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "n_samples = 20000\n",
    "\n",
    "# Create array holding predictive feature\n",
    "X1 = 4 * rand(n_samples) - 2\n",
    "X2 = 4 * rand(n_samples) - 2\n",
    "# Create y. you should have X in the expression for y\n",
    "y = X1 * X2\n",
    "\n",
    "\n",
    "# create dataframe because pdp_isolate expects a dataFrame as an argument\n",
    "my_df = pd.DataFrame({'X1': X1, 'X2': X2, 'y': y})\n",
    "predictors_df = my_df.drop(['y'], axis=1)\n",
    "\n",
    "my_model = RandomForestRegressor(n_estimators=30, random_state=1).fit(predictors_df, my_df.y)\n",
    "\n",
    "\n",
    "pdp_dist = pdp.pdp_isolate(model=my_model, dataset=my_df, model_features=['X1', 'X2'], feature='X1')\n",
    "pdp.pdp_plot(pdp_dist, 'X1')\n",
    "plt.show()\n",
    "\n",
    "perm = PermutationImportance(my_model).fit(predictors_df, my_df.y)\n",
    "\n",
    "# show the weights for the permutation importance you just calculated\n",
    "eli5.show_weights(perm, feature_names = ['X1', 'X2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d067bcc392e2e8f2fe54118d11b7500c7a413fba"
   },
   "source": [
    "## Congrats\n",
    "\n",
    "Partial dependence plots can be really interesting. We have a [discussion thread](https://www.kaggle.com/learn-forum/65782) to talk about what real-world topics or questions you'd be curious to see addressed with partial dependence plots. \n",
    "\n",
    "Next up is **SHAP values** which help you understand the logic for each individual prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
