{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "79990a079791035acbf2936c71f31eea394cf2d4"
   },
   "source": [
    "# Exercises\n",
    "\n",
    "## Set Up\n",
    "\n",
    "At this point, you have enough tools to put together compelling solutions to real-world problems. You will ned to pick the right techniques for each part of the following data science scenario. Along the way, you'll use SHAP values along with your other insights tools.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "74447999bb7b4cfac1e3a1bd22aacf600cfe4c3f"
   },
   "source": [
    "## The Scenario\n",
    "A hospital has struggled with \"readmissions,\" where they release a patient before the patient has recovered enough, and the patient returns with health complications. \n",
    "\n",
    "The hospital wants your help identifying patients at highest risk of being readmitted. Doctors (rather than your model) will make the final decision about when to release each patient; but they hope your model will highlight issues the doctors should consider when releasing a patient.\n",
    "\n",
    "The hospital has given you relevant patient medical information.  Here is a list of columns in the data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9573b94d6539467027551556b990a63b5a64ec55"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../Machine_Learning_for_Insights_challenge_Kaggle/Medical Data and Hospital Readmissions.csv')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "894e879e82c550db4df09dc68baefc798387f37b"
   },
   "source": [
    "Here are some quick hints at interpreting the field names:\n",
    "\n",
    "- Your prediction target is `readmitted`\n",
    "- Columns with the word `diag` indicate the diagnostic code of the illness or illnesses the patient was admitted with. For example, `diag_1_428` means the doctor said their first illness diagnosis is number \"428\".  What illness does 428 correspond to? You could look it up in a codebook, but without more medical background it wouldn't mean anything to you anyway.\n",
    "- A column names like `glimepiride_No` mean the patient did not have the medicine `glimepiride`. If this feature had a value of False, then the patient did take the drug `glimepiride`\n",
    "- Features whose names begin with `medical_specialty` describe the specialty of the doctor seeing the patient. The values in these fields are all `True` or `False`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d9b47941e2e951d54e19968640ab4efd33cf2fe4"
   },
   "source": [
    "## Your Code Library\n",
    "As you write code to work through this scenario, these code snippets from previous tutorials may be useful. You'll still need to modify them, but we've copied them here to save you from having to look them up.\n",
    "\n",
    "**Calculate and show permutation importance:**\n",
    "```\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(my_model, random_state=1).fit(val_X, val_y)\n",
    "eli5.show_weights(perm, feature_names = val_X.columns.tolist())\n",
    "```\n",
    "\n",
    "**Calculate and show partial dependence plot:**\n",
    "```\n",
    "from matplotlib import pyplot as plt\n",
    "from pdpbox import pdp, get_dataset, info_plots\n",
    "\n",
    "# Create the data that we will plot\n",
    "pdp_goals = pdp.pdp_isolate(model=my_model, dataset=val_X, model_features=feature_names, feature='Goal Scored')\n",
    "\n",
    "# plot it\n",
    "pdp.pdp_plot(pdp_goals, 'Goal Scored')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**Calculate and show Shap Values for One Prediction:**\n",
    "```\n",
    "import shap  # package used to calculate Shap values\n",
    "\n",
    "data_for_prediction = val_X.iloc[0,:]  # use 1 row of data here. Could use multiple rows if desired\n",
    "\n",
    "# Create object that can calculate shap values\n",
    "explainer = shap.TreeExplainer(my_model)\n",
    "shap_values = explainer.shap_values(data_for_prediction)\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0], data_for_prediction)\n",
    "```\n",
    "\n",
    "## Step 1:\n",
    "You have built a simple model, but the doctors say they don't know how to evaluate a model, and they'd like you to show them some evidence the model is doing something in line with their medical intuition. Create any graphics or tables that will show them a quick overview of what the model is doing?\n",
    "\n",
    "They are very busy. So they want you to condense your model overview into just 1 or 2 graphics, rather than a long string of graphics.\n",
    "\n",
    "We'll start after the point where you've built a basic model. Just run the following cell to build the model called `my_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "70cd16ef19ca8ca59d6acdb109ba493f6592d276"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = pd.read_csv('../Machine_Learning_for_Insights_challenge_Kaggle/Medical Data and Hospital Readmissions.csv')\n",
    "\n",
    "y = data.readmitted\n",
    "#print(y)\n",
    "\n",
    "base_features = [c for c in data.columns if c != \"readmitted\"]\n",
    "\n",
    "X = data[base_features]\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "#print(val_y)\n",
    "my_model = RandomForestClassifier(n_estimators=30, random_state=1).fit(train_X, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "efe4867622856ac975c5ee5f3040318880bf7ca9"
   },
   "outputs": [],
   "source": [
    "# Lets read the data a bit more\n",
    "\n",
    "print(val_X[:6])\n",
    "row_to_show = 5\n",
    "data_for_prediction = val_X.iloc[row_to_show]  # use 1 row of data here. Could use multiple rows if desired\n",
    "print(data_for_prediction)\n",
    "data_for_prediction_array = data_for_prediction.values.reshape(1, -1)\n",
    "print(data_for_prediction_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "034d69e4679652c28bc259423bf835b538c7f44c"
   },
   "source": [
    "Now use the following cell to create the materials for the doctors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "72cc3c5535db757cb32689661ad61bb959f4ffdf"
   },
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(my_model, random_state=1).fit(val_X, val_y)\n",
    "eli5.show_weights(perm, feature_names = val_X.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9ec7cc5d744365fc25f294b5a8739475239cf1ca"
   },
   "source": [
    "## Step 2\n",
    "\n",
    "It appears `number_inpatient` is a really important feature. The doctors would like to know more about that. Create a graph for them that shows how `num_inpatient` affects the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4c9a4b499e3a5c98460a1502715cbe8b817fc5ab"
   },
   "outputs": [],
   "source": [
    "# PDP for number_inpatient feature\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from pdpbox import pdp, get_dataset, info_plots\n",
    "\n",
    "feature_name = 'number_inpatient'\n",
    "# Create the data that we will plot\n",
    "my_pdp = pdp.pdp_isolate(model=my_model, dataset=val_X, model_features=val_X.columns, feature=feature_name)\n",
    "\n",
    "# plot it\n",
    "pdp.pdp_plot(my_pdp, feature_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c4ffc694d43bc1a6bb0029849a3e488b6667c667"
   },
   "source": [
    "## Step 3\n",
    "\n",
    "The doctors think it's a good sign that increasing the number of inpatient procedures leads to increased predictions.  But they can't tell from this plot whether that change in the plot is big or small. They'd like you to create something similar for `time_in_hospital` to see how that compares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "106e5046a5aefdfa5a1a7a871192255cf98da22a"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from pdpbox import pdp, get_dataset, info_plots\n",
    "\n",
    "feature_name = 'time_in_hospital'\n",
    "# Create the data that we will plot\n",
    "my_pdp = pdp.pdp_isolate(model=my_model, dataset=val_X, model_features=val_X.columns, feature=feature_name)\n",
    "\n",
    "# plot it\n",
    "pdp.pdp_plot(my_pdp, feature_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ab039b9f08ab44ae323932e5bb15eaccae29bb15"
   },
   "source": [
    "## Step 4\n",
    "\n",
    "Woah!  It seems like `time_in_hospital` doesn't matter at all.  The difference between the lowest value on the partial dependence plot and the highest value is about 5%.\n",
    "\n",
    "If that is what your model concluded, the doctors will believe it. But it seems so low. Could  the data be wrong, or is your model doing something more complex than they expect?  \n",
    "\n",
    "They'd like you to show them the raw readmission rate for each value of `time_in_hospital` to see how it compares to the partial dependence plot.\n",
    "\n",
    "- Make that plot. \n",
    "- Are the results similar or different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a772975303c37b726c192ff74938773520354fb"
   },
   "outputs": [],
   "source": [
    "# A simple pandas groupby showing the average readmission rate for each time_in_hospital.\n",
    "\n",
    "# Do concat to keep validation data separate, rather than using all original data\n",
    "all_train = pd.concat([train_X, train_y], axis=1)\n",
    "\n",
    "all_train.groupby(['time_in_hospital']).mean().readmitted.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "631c01864adce8997a39b0b5446bf563da8b03e0"
   },
   "source": [
    "## Step 5\n",
    "Now the doctors are convinced you have the right data, and the model overview looked reasonable.  It's time to turn this into a finished product they can use. Specifically, the hospital wants you to create a function `patient_risk_factors` that does the following\n",
    "- Takes a single row with patient data (of the same format you as your raw data)\n",
    "- Creates a visualization showing what features of that patient increased their risk of readmission, what features decreased it, and how much those features mattered.\n",
    "\n",
    "It's not important to show every feature with every miniscule impact on the readmission risk.  It's fine to focus on only the most important features for that patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b619178f57763bb3d852d51c3cdf017b61083614"
   },
   "outputs": [],
   "source": [
    "import shap  # package used to calculate Shap values\n",
    "\n",
    "sample_data_for_prediction = val_X.iloc[0].astype(float)  # to test function\n",
    "\n",
    "def patient_risk_factors(model, patient_data):\n",
    "    # Create object that can calculate shap values\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(patient_data)\n",
    "    shap.initjs()\n",
    "    return shap.force_plot(explainer.expected_value[1], shap_values[1], patient_data)\n",
    "\n",
    "patient_risk_factors(my_model, sample_data_for_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5bbb9af9185ca7e88994761ec7f65c3fdeae47c8"
   },
   "source": [
    "## Congrats\n",
    "You have some powerful tools to get insights about both models and individual predictions. Next up, we will look at aggregated SHAP values to link the model-level and prediction-level insights."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
