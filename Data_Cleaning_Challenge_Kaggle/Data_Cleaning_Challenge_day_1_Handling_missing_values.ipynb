{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "b91a74ba-85f4-486e-b5f9-d0898f0626bf",
        "_uuid": "6ac53f18b4f4ec0fc44348cedb5d1c319fa127c0"
      },
      "cell_type": "markdown",
      "source": "### All days of the challange:\n\n* [Day 1: Handling missing values](https://www.kaggle.com/rtatman/data-cleaning-challenge-handling-missing-values)\n* [Day 2: Scaling and normalization](https://www.kaggle.com/rtatman/data-cleaning-challenge-scale-and-normalize-data)\n* [Day 3: Parsing dates](https://www.kaggle.com/rtatman/data-cleaning-challenge-parsing-dates/)\n* [Day 4: Character encodings](https://www.kaggle.com/rtatman/data-cleaning-challenge-character-encodings/)\n* [Day 5: Inconsistent Data Entry](https://www.kaggle.com/rtatman/data-cleaning-challenge-inconsistent-data-entry/)\n___\nWelcome to day 1 of the 5-Day Data Challenge! Today, we're going to be looking at how to deal with missing values. To get started, click the blue \"Fork Notebook\" button in the upper, right hand corner. This will create a private copy of this notebook that you can edit and play with. Once you're finished with the exercises, you can choose to make your notebook public to share with others. :)\n\n> **Your turn!** As we work through this notebook, you'll see some notebook cells (a block of either code or text) that has \"Your Turn!\" written in it. These are exercises for you to do to help cement your understanding of the concepts we're talking about. Once you've written the code to answer a specific question, you can run the code by clicking inside the cell (box with code in it) with the code you want to run and then hit CTRL + ENTER (CMD + ENTER on a Mac). You can also click in a cell and then click on the right \"play\" arrow to the left of the code. If you want to run all the code in your notebook, you can use the double, \"fast forward\" arrows at the bottom of the notebook editor.\n\nHere's what we're going to do today:\n\n* [Take a first look at the data](#Take-a-first-look-at-the-data)\n* [See how many missing data points we have](#See-how-many-missing-data-points-we-have)\n* [Figure out why the data is missing](#Figure-out-why-the-data-is-missing)\n* [Drop missing values](#Drop-missing-values)\n* [Filling in missing values](#Filling-in-missing-values)\n\nLet's get started!"
    },
    {
      "metadata": {
        "_cell_guid": "5cd5061f-ae30-4837-a53b-690ffd5c5830",
        "_uuid": "9d82bf13584b8e682962fbb96131f2447d741679"
      },
      "cell_type": "markdown",
      "source": "# Take a first look at the data\n________\n\nThe first thing we'll need to do is load in the libraries and datasets we'll be using. For today, I'll be using a dataset of events that occured in American Football games for demonstration, and you'll be using a dataset of building permits issued in San Francisco.\n\n> **Important!** Make sure you run this cell yourself or the rest of your code won't work!"
    },
    {
      "metadata": {
        "_cell_guid": "135a7804-b5f5-40aa-8657-4a15774e3666",
        "_uuid": "835cbe0834b935fb0fd40c75b9c39454836f4d5f",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# modules we'll use\nimport pandas as pd\nimport numpy as np\n\n# read in all our data\nnfl_data = pd.read_csv(\"../input/nflplaybyplay2009to2016/NFL Play by Play 2009-2017 (v4).csv\")\nsf_permits = pd.read_csv(\"../input/building-permit-applications-data/Building_Permits.csv\")\n\n# set seed for reproducibility\nnp.random.seed(0) ",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (25,51) have mixed types. Specify dtype option on import or set low_memory=False.\n  interactivity=interactivity, compiler=compiler, result=result)\n/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (22,32) have mixed types. Specify dtype option on import or set low_memory=False.\n  interactivity=interactivity, compiler=compiler, result=result)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "09b58d03-d34d-497a-b298-12a0ae962e3d",
        "_uuid": "53c84bf86149ac41b237633a1a79d6130d6a2cd4"
      },
      "cell_type": "markdown",
      "source": "The first thing I do when I get a new dataset is take a look at some of it. This lets me see that it all read in correctly and get an idea of what's going on with the data. In this case, I'm looking to see if I see any missing values, which will be reprsented with `NaN` or `None`."
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# look at a few rows of the nfl_data file. I can see a handful of missing data already!\n#nfl_data.sample(5)\nnfl_data.sample(4)",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "              Date      GameID  Drive  qtr  down   time  TimeUnder  TimeSecs  \\\n402617  2017-12-24  2017122403      3    1   1.0  07:26          8    3146.0   \n120868  2011-12-04  2011120409      9    1   2.0  00:55          1    2755.0   \n292925  2015-11-08  2015110804      4    1   1.0  08:45          9    3225.0   \n125034  2011-12-11  2011121111     13    3   3.0  13:05         14    1685.0   \n\n        PlayTimeDiff SideofField   ...      yacEPA  Home_WP_pre  Away_WP_pre  \\\n402617          41.0          KC   ...         NaN     0.493037     0.506963   \n120868          29.0         DEN   ...         NaN     0.462295     0.537705   \n292925           5.0         MIA   ...    2.683448     0.782842     0.217158   \n125034           0.0         DEN   ...   -0.963514     0.531082     0.468918   \n\n        Home_WP_post  Away_WP_post  Win_Prob       WPA    airWPA    yacWPA  \\\n402617      0.491550      0.508450  0.506963  0.001488       NaN       NaN   \n120868      0.478892      0.521108  0.537705 -0.016597       NaN       NaN   \n292925      0.744232      0.255768  0.217158  0.038610 -0.031553  0.070163   \n125034      0.479938      0.520062  0.531082 -0.051143 -0.020857 -0.030287   \n\n        Season  \n402617    2017  \n120868    2011  \n292925    2015  \n125034    2011  \n\n[4 rows x 102 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>GameID</th>\n      <th>Drive</th>\n      <th>qtr</th>\n      <th>down</th>\n      <th>time</th>\n      <th>TimeUnder</th>\n      <th>TimeSecs</th>\n      <th>PlayTimeDiff</th>\n      <th>SideofField</th>\n      <th>...</th>\n      <th>yacEPA</th>\n      <th>Home_WP_pre</th>\n      <th>Away_WP_pre</th>\n      <th>Home_WP_post</th>\n      <th>Away_WP_post</th>\n      <th>Win_Prob</th>\n      <th>WPA</th>\n      <th>airWPA</th>\n      <th>yacWPA</th>\n      <th>Season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>402617</th>\n      <td>2017-12-24</td>\n      <td>2017122403</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>07:26</td>\n      <td>8</td>\n      <td>3146.0</td>\n      <td>41.0</td>\n      <td>KC</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.493037</td>\n      <td>0.506963</td>\n      <td>0.491550</td>\n      <td>0.508450</td>\n      <td>0.506963</td>\n      <td>0.001488</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>120868</th>\n      <td>2011-12-04</td>\n      <td>2011120409</td>\n      <td>9</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>00:55</td>\n      <td>1</td>\n      <td>2755.0</td>\n      <td>29.0</td>\n      <td>DEN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.462295</td>\n      <td>0.537705</td>\n      <td>0.478892</td>\n      <td>0.521108</td>\n      <td>0.537705</td>\n      <td>-0.016597</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2011</td>\n    </tr>\n    <tr>\n      <th>292925</th>\n      <td>2015-11-08</td>\n      <td>2015110804</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>08:45</td>\n      <td>9</td>\n      <td>3225.0</td>\n      <td>5.0</td>\n      <td>MIA</td>\n      <td>...</td>\n      <td>2.683448</td>\n      <td>0.782842</td>\n      <td>0.217158</td>\n      <td>0.744232</td>\n      <td>0.255768</td>\n      <td>0.217158</td>\n      <td>0.038610</td>\n      <td>-0.031553</td>\n      <td>0.070163</td>\n      <td>2015</td>\n    </tr>\n    <tr>\n      <th>125034</th>\n      <td>2011-12-11</td>\n      <td>2011121111</td>\n      <td>13</td>\n      <td>3</td>\n      <td>3.0</td>\n      <td>13:05</td>\n      <td>14</td>\n      <td>1685.0</td>\n      <td>0.0</td>\n      <td>DEN</td>\n      <td>...</td>\n      <td>-0.963514</td>\n      <td>0.531082</td>\n      <td>0.468918</td>\n      <td>0.479938</td>\n      <td>0.520062</td>\n      <td>0.531082</td>\n      <td>-0.051143</td>\n      <td>-0.020857</td>\n      <td>-0.030287</td>\n      <td>2011</td>\n    </tr>\n  </tbody>\n</table>\n<p>4 rows Ã— 102 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "604ac3a4-b1d9-4264-b312-4bbeecdeec00",
        "_uuid": "03ce3b4afe87d98f777172c2c7be066a66a0b237"
      },
      "cell_type": "markdown",
      "source": "Yep, it looks like there's some missing values. What about in the sf_permits dataset?"
    },
    {
      "metadata": {
        "_cell_guid": "8dca377c-95be-40ec-87dc-61a8fca750e2",
        "_uuid": "e389495bb2e5d27ab632d5f3648ca1f912c94706",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# your turn! Look at a couple of rows from the sf_permits dataset. Do you notice any missing data?\n\nsf_permits.sample(5)",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "       Permit Number  Permit Type  Permit Type Definition  \\\n80861   201503312464            8  otc alterations permit   \n77426   201502279625            8  otc alterations permit   \n116799       M670287            8  otc alterations permit   \n12447   201305146832            8  otc alterations permit   \n122764  201605026315            8  otc alterations permit   \n\n       Permit Creation Date Block  Lot  Street Number Street Number Suffix  \\\n80861            03/31/2015  5556  047            331                  NaN   \n77426            02/27/2015  4209  007           1144                  NaN   \n116799           03/08/2016  1671  015           2715                  NaN   \n12447            05/14/2013  5632  009             50                  NaN   \n122764           05/02/2016  3750  079            633                  NaN   \n\n       Street Name Street Suffix      ...        Existing Construction Type  \\\n80861    Franconia            St      ...                               5.0   \n77426         York            St      ...                               5.0   \n116799    Cabrillo            St      ...                               NaN   \n12447     Bradford            St      ...                               5.0   \n122764      Folsom            St      ...                               1.0   \n\n       Existing Construction Type Description Proposed Construction Type  \\\n80861                          wood frame (5)                        5.0   \n77426                          wood frame (5)                        5.0   \n116799                                    NaN                        NaN   \n12447                          wood frame (5)                        5.0   \n122764                          constr type 1                        1.0   \n\n       Proposed Construction Type Description Site Permit Supervisor District  \\\n80861                          wood frame (5)         NaN                 9.0   \n77426                          wood frame (5)         NaN                 9.0   \n116799                                    NaN         NaN                 1.0   \n12447                          wood frame (5)         NaN                 9.0   \n122764                          constr type 1         NaN                 6.0   \n\n       Neighborhoods - Analysis Boundaries  Zipcode  \\\n80861                       Bernal Heights  94110.0   \n77426                              Mission  94110.0   \n116799                      Outer Richmond  94121.0   \n12447                       Bernal Heights  94110.0   \n122764      Financial District/South Beach  94107.0   \n\n                                        Location      Record ID  \n80861   (37.74442565025791, -122.40754848370753)  1376419432622  \n77426   (37.75367753539216, -122.40854634744491)  1372753272698  \n116799   (37.77402649497712, -122.4879208672526)  1415144410419  \n12447   (37.74256334185832, -122.40957339827986)  1304634185311  \n122764  (37.78447130006642, -122.39718137365679)  1421674165834  \n\n[5 rows x 43 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Permit Number</th>\n      <th>Permit Type</th>\n      <th>Permit Type Definition</th>\n      <th>Permit Creation Date</th>\n      <th>Block</th>\n      <th>Lot</th>\n      <th>Street Number</th>\n      <th>Street Number Suffix</th>\n      <th>Street Name</th>\n      <th>Street Suffix</th>\n      <th>...</th>\n      <th>Existing Construction Type</th>\n      <th>Existing Construction Type Description</th>\n      <th>Proposed Construction Type</th>\n      <th>Proposed Construction Type Description</th>\n      <th>Site Permit</th>\n      <th>Supervisor District</th>\n      <th>Neighborhoods - Analysis Boundaries</th>\n      <th>Zipcode</th>\n      <th>Location</th>\n      <th>Record ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>80861</th>\n      <td>201503312464</td>\n      <td>8</td>\n      <td>otc alterations permit</td>\n      <td>03/31/2015</td>\n      <td>5556</td>\n      <td>047</td>\n      <td>331</td>\n      <td>NaN</td>\n      <td>Franconia</td>\n      <td>St</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>wood frame (5)</td>\n      <td>5.0</td>\n      <td>wood frame (5)</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>Bernal Heights</td>\n      <td>94110.0</td>\n      <td>(37.74442565025791, -122.40754848370753)</td>\n      <td>1376419432622</td>\n    </tr>\n    <tr>\n      <th>77426</th>\n      <td>201502279625</td>\n      <td>8</td>\n      <td>otc alterations permit</td>\n      <td>02/27/2015</td>\n      <td>4209</td>\n      <td>007</td>\n      <td>1144</td>\n      <td>NaN</td>\n      <td>York</td>\n      <td>St</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>wood frame (5)</td>\n      <td>5.0</td>\n      <td>wood frame (5)</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>Mission</td>\n      <td>94110.0</td>\n      <td>(37.75367753539216, -122.40854634744491)</td>\n      <td>1372753272698</td>\n    </tr>\n    <tr>\n      <th>116799</th>\n      <td>M670287</td>\n      <td>8</td>\n      <td>otc alterations permit</td>\n      <td>03/08/2016</td>\n      <td>1671</td>\n      <td>015</td>\n      <td>2715</td>\n      <td>NaN</td>\n      <td>Cabrillo</td>\n      <td>St</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>Outer Richmond</td>\n      <td>94121.0</td>\n      <td>(37.77402649497712, -122.4879208672526)</td>\n      <td>1415144410419</td>\n    </tr>\n    <tr>\n      <th>12447</th>\n      <td>201305146832</td>\n      <td>8</td>\n      <td>otc alterations permit</td>\n      <td>05/14/2013</td>\n      <td>5632</td>\n      <td>009</td>\n      <td>50</td>\n      <td>NaN</td>\n      <td>Bradford</td>\n      <td>St</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>wood frame (5)</td>\n      <td>5.0</td>\n      <td>wood frame (5)</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>Bernal Heights</td>\n      <td>94110.0</td>\n      <td>(37.74256334185832, -122.40957339827986)</td>\n      <td>1304634185311</td>\n    </tr>\n    <tr>\n      <th>122764</th>\n      <td>201605026315</td>\n      <td>8</td>\n      <td>otc alterations permit</td>\n      <td>05/02/2016</td>\n      <td>3750</td>\n      <td>079</td>\n      <td>633</td>\n      <td>NaN</td>\n      <td>Folsom</td>\n      <td>St</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>constr type 1</td>\n      <td>1.0</td>\n      <td>constr type 1</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>Financial District/South Beach</td>\n      <td>94107.0</td>\n      <td>(37.78447130006642, -122.39718137365679)</td>\n      <td>1421674165834</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 43 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "33656c2b-a74e-4b76-9af2-d7ecd518577b",
        "_uuid": "400b025f618cc76a39fec2537193f28ba1e49168"
      },
      "cell_type": "markdown",
      "source": "# See how many missing data points we have\n___\n\nOk, now we know that we do have some missing values. Let's see how many we have in each column. "
    },
    {
      "metadata": {
        "_cell_guid": "a69ac02d-197b-487b-a38f-2f853d208eed",
        "_uuid": "6dc0e32180c4a3bba003e7886faf126d93affadf",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# get the number of missing data points per column\nmissing_values_count_nfl = nfl_data.isnull().sum()\n\n# look at the # of missing points in the first ten columns\nprint(missing_values_count_nfl)",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Date                                0\nGameID                              0\nDrive                               0\nqtr                                 0\ndown                            61154\ntime                              224\nTimeUnder                           0\nTimeSecs                          224\nPlayTimeDiff                      444\nSideofField                       528\nyrdln                             840\nyrdline100                        840\nydstogo                             0\nydsnet                              0\nGoalToGo                          840\nFirstDown                       28811\nposteam                         24992\nDefensiveTeam                   24992\ndesc                                2\nPlayAttempted                       0\nYards.Gained                        0\nsp                                  0\nTouchdown                           0\nExPointResult                  397578\nTwoPointConv                   407083\nDefTwoPoint                    407664\nSafety                              0\nOnsidekick                          0\nPuntResult                     385317\nPlayType                            0\n                                ...  \nAwayTeam                            0\nTimeout_Indicator                   0\nTimeout_Team                        0\nposteam_timeouts_pre                0\nHomeTimeouts_Remaining_Pre          0\nAwayTimeouts_Remaining_Pre          0\nHomeTimeouts_Remaining_Post         0\nAwayTimeouts_Remaining_Post         0\nNo_Score_Prob                     176\nOpp_Field_Goal_Prob               176\nOpp_Safety_Prob                   176\nOpp_Touchdown_Prob                176\nField_Goal_Prob                   176\nSafety_Prob                       176\nTouchdown_Prob                    176\nExPoint_Prob                        0\nTwoPoint_Prob                       0\nExpPts                            176\nEPA                               369\nairEPA                         248394\nyacEPA                         248498\nHome_WP_pre                     24954\nAway_WP_pre                     24954\nHome_WP_post                    26587\nAway_WP_post                    26587\nWin_Prob                        25009\nWPA                              5541\nairWPA                         248501\nyacWPA                         248762\nSeason                              0\nLength: 102, dtype: int64\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "84455c7e-6c63-4e08-a7b4-7520a61072f9",
        "_uuid": "054ba8782a7b0555336eddb90c985fb638beac4d"
      },
      "cell_type": "markdown",
      "source": "That seems like a lot! It might be helpful to see what percentage of the values in our dataset were missing to give us a better sense of the scale of this problem:"
    },
    {
      "metadata": {
        "_cell_guid": "fb77dd56-192e-48be-8181-2082985dd5a2",
        "_uuid": "d6e65ba197893f29d9dce0b0cd1c75017b60db09",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# how many total missing values do we have?\ntotal_cells_nfl = np.product(nfl_data.shape)\ntotal_missing_nfl = missing_values_count_nfl.sum()\n\n# percent of data that is missing\npercentage_missign_values_nfl = (total_missing_nfl/total_cells_nfl) * 100\nprint(percentage_missign_values_nfl)",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": "24.87214126835169\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "31daa324-9215-4930-985c-01dee717b6b8",
        "_uuid": "3331fa42efa16f3db2e8e196411f351c5f8309f5"
      },
      "cell_type": "markdown",
      "source": "Wow, almost a quarter of the cells in this dataset are empty! In the next step, we're going to take a closer look at some of the columns with missing values and try to figure out what might be going on with them."
    },
    {
      "metadata": {
        "_cell_guid": "f20a9474-41ee-4ecd-a2f4-1ab147fc8655",
        "_uuid": "64487760aa1afaaa8b8a4d1f95206773759db101",
        "trusted": true,
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "# your turn! Find out what percent of the sf_permits dataset is missing\n\nmissing_values_count_sf = sf_permits.isnull().sum()\n\n# look at the # of missing points in the first ten columns\nprint(missing_values_count_sf)\n\n\n# how many total missing values do we have?\ntotal_cells_sf = np.product(sf_permits.shape)\ntotal_missing_sf = missing_values_count_sf.sum()\n\n# percent of data that is missing\npercentage_missign_values_sf = (total_missing_sf/total_cells_sf) * 100\n",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Permit Number                                  0\nPermit Type                                    0\nPermit Type Definition                         0\nPermit Creation Date                           0\nBlock                                          0\nLot                                            0\nStreet Number                                  0\nStreet Number Suffix                      196684\nStreet Name                                    0\nStreet Suffix                               2768\nUnit                                      169421\nUnit Suffix                               196939\nDescription                                  290\nCurrent Status                                 0\nCurrent Status Date                            0\nFiled Date                                     0\nIssued Date                                14940\nCompleted Date                            101709\nFirst Construction Document Date           14946\nStructural Notification                   191978\nNumber of Existing Stories                 42784\nNumber of Proposed Stories                 42868\nVoluntary Soft-Story Retrofit             198865\nFire Only Permit                          180073\nPermit Expiration Date                     51880\nEstimated Cost                             38066\nRevised Cost                                6066\nExisting Use                               41114\nExisting Units                             51538\nProposed Use                               42439\nProposed Units                             50911\nPlansets                                   37309\nTIDF Compliance                           198898\nExisting Construction Type                 43366\nExisting Construction Type Description     43366\nProposed Construction Type                 43162\nProposed Construction Type Description     43162\nSite Permit                               193541\nSupervisor District                         1717\nNeighborhoods - Analysis Boundaries         1725\nZipcode                                     1716\nLocation                                    1700\nRecord ID                                      0\ndtype: int64\n26.26002315058403\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4b7b869c99b5efa264d4772db774662e5fd79130"
      },
      "cell_type": "code",
      "source": "print(percentage_missign_values_sf)",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": "26.26002315058403\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "62b9f021-5b80-43e2-bf60-8e0d5e22d572",
        "_uuid": "032a618abb98a28e60ab84376cf21402178f995d"
      },
      "cell_type": "markdown",
      "source": "# Figure out why the data is missing\n____\n \nThis is the point at which we get into the part of data science that I like to call \"data intution\", by which I mean \"really looking at your data and trying to figure out why it is the way it is and how that will affect your analysis\". It can be a frustrating part of data science, especially if you're newer to the field and don't have a lot of experience. For dealing with missing values, you'll need to use your intution to figure out why the value is missing. One of the most important question you can ask yourself to help figure this out is this:\n\n> **Is this value missing becuase it wasn't recorded or becuase it dosen't exist?**\n\nIf a value is missing becuase it doens't exist (like the height of the oldest child of someone who doesn't have any children) then it doesn't make sense to try and guess what it might be. These values you probalby do want to keep as NaN. On the other hand, if a value is missing becuase it wasn't recorded, then you can try to guess what it might have been based on the other values in that column and row. (This is called \"imputation\" and we'll learn how to do it next! :)\n\nLet's work through an example. Looking at the number of missing values in the nfl_data dataframe, I notice that the column `TimesSec` has a lot of missing values in it: "
    },
    {
      "metadata": {
        "_cell_guid": "77739e82-8d32-4374-84bf-a924b6065168",
        "_uuid": "b65aea6046964806e44422c057bce8bd7f8e59d5",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# look at the # of missing points in the first ten columns\nmissing_values_count[0:10]",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 52,
          "data": {
            "text/plain": "Date                                0\nGameID                              0\nDrive                               0\nqtr                                 0\ndown                            61154\ntime                              224\nTimeUnder                           0\nTimeSecs                          224\nPlayTimeDiff                      444\nSideofField                       528\nyrdln                             840\nyrdline100                        840\nydstogo                             0\nydsnet                              0\nGoalToGo                          840\nFirstDown                       28811\nposteam                         24992\nDefensiveTeam                   24992\ndesc                                2\nPlayAttempted                       0\nYards.Gained                        0\nsp                                  0\nTouchdown                           0\nExPointResult                  397578\nTwoPointConv                   407083\nDefTwoPoint                    407664\nSafety                              0\nOnsidekick                          0\nPuntResult                     385317\nPlayType                            0\n                                ...  \nAwayTeam                            0\nTimeout_Indicator                   0\nTimeout_Team                        0\nposteam_timeouts_pre                0\nHomeTimeouts_Remaining_Pre          0\nAwayTimeouts_Remaining_Pre          0\nHomeTimeouts_Remaining_Post         0\nAwayTimeouts_Remaining_Post         0\nNo_Score_Prob                     176\nOpp_Field_Goal_Prob               176\nOpp_Safety_Prob                   176\nOpp_Touchdown_Prob                176\nField_Goal_Prob                   176\nSafety_Prob                       176\nTouchdown_Prob                    176\nExPoint_Prob                        0\nTwoPoint_Prob                       0\nExpPts                            176\nEPA                               369\nairEPA                         248394\nyacEPA                         248498\nHome_WP_pre                     24954\nAway_WP_pre                     24954\nHome_WP_post                    26587\nAway_WP_post                    26587\nWin_Prob                        25009\nWPA                              5541\nairWPA                         248501\nyacWPA                         248762\nSeason                              0\nLength: 102, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "1b17f4c9-dcab-4857-82f9-a2534e804c91",
        "_uuid": "5cff158285ab37a89b80dcc35d5c690cdb42d3a4"
      },
      "cell_type": "markdown",
      "source": "By looking at [the documentation](https://www.kaggle.com/maxhorowitz/nflplaybyplay2009to2016), I can see that this column has information on the number of seconds left in the game when the play was made. This means that these values are probably missing because they were not recorded, rather than because they don't exist. So, it would make sense for us to try and guess what they should be rather than just leaving them as NA's.\n\nOn the other hand, there are other fields, like `PenalizedTeam` that also have lot of missing fields. In this case, though, the field is missing because if there was no penalty then it doesn't make sense to say *which* team was penalized. For this column, it would make more sense to either leave it empty or to add a third value like \"neither\" and use that to replace the NA's.\n\n> **Tip:** This is a great place to read over the dataset documentation if you haven't already! If you're working with a dataset that you've gotten from another person, you can also try reaching out to them to get more information.\n\nIf you're doing very careful data analysis, this is the point at which you'd look at each column individually to figure out the best strategy for filling those missing values. For the rest of this notebook, we'll cover some \"quick and dirty\" techniques that can help you with missing values but will probably also end up removing some useful information or adding some noise to your data.\n\n## Your turn!\n\n* Look at the columns `Street Number Suffix` and `Zipcode` from the `sf_permits` datasets. Both of these contain missing values. Which, if either, of these are missing because they don't exist? Which, if either, are missing because they weren't recorded?"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "02cc281f8edeb19b576ff93361fe4da5753e7790"
      },
      "cell_type": "code",
      "source": "print(sf_permits['Street Number Suffix'])",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": "0         NaN\n1         NaN\n2         NaN\n3         NaN\n4         NaN\n5         NaN\n6         NaN\n7         NaN\n8         NaN\n9         NaN\n10        NaN\n11        NaN\n12        NaN\n13        NaN\n14        NaN\n15        NaN\n16        NaN\n17        NaN\n18        NaN\n19        NaN\n20        NaN\n21        NaN\n22        NaN\n23        NaN\n24        NaN\n25        NaN\n26        NaN\n27        NaN\n28        NaN\n29        NaN\n         ... \n198870    NaN\n198871    NaN\n198872    NaN\n198873    NaN\n198874    NaN\n198875    NaN\n198876    NaN\n198877    NaN\n198878    NaN\n198879    NaN\n198880    NaN\n198881    NaN\n198882    NaN\n198883    NaN\n198884    NaN\n198885    NaN\n198886    NaN\n198887    NaN\n198888    NaN\n198889    NaN\n198890    NaN\n198891    NaN\n198892    NaN\n198893    NaN\n198894    NaN\n198895    NaN\n198896    NaN\n198897    NaN\n198898    NaN\n198899    NaN\nName: Street Number Suffix, Length: 198900, dtype: object\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "edcadc892b98dde34b6e62f018b8d04f3680114b"
      },
      "cell_type": "code",
      "source": "sf_permits['Street Number Suffix'].isnull().sum()\n# All values are missing which apparently indicates that this value is supposed to be missing",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 39,
          "data": {
            "text/plain": "196684"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "e2492670df9df2b3c678cafb0eefb05e39d484eb"
      },
      "cell_type": "code",
      "source": "print(sf_permits['Zipcode'])",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": "0         94102.0\n1         94102.0\n2         94109.0\n3         94109.0\n4         94102.0\n5         94107.0\n6         94122.0\n7         94124.0\n8         94117.0\n9         94117.0\n10        94114.0\n11        94102.0\n12        94114.0\n13        94131.0\n14        94115.0\n15        94108.0\n16        94104.0\n17        94114.0\n18        94123.0\n19        94114.0\n20        94117.0\n21        94110.0\n22        94133.0\n23        94123.0\n24        94123.0\n25        94122.0\n26        94121.0\n27        94117.0\n28        94122.0\n29        94102.0\n           ...   \n198870    94109.0\n198871    94117.0\n198872    94114.0\n198873    94110.0\n198874    94131.0\n198875    94102.0\n198876    94117.0\n198877    94112.0\n198878    94110.0\n198879    94112.0\n198880    94122.0\n198881    94133.0\n198882    94112.0\n198883    94102.0\n198884    94103.0\n198885    94116.0\n198886        NaN\n198887        NaN\n198888        NaN\n198889        NaN\n198890        NaN\n198891        NaN\n198892        NaN\n198893        NaN\n198894        NaN\n198895        NaN\n198896        NaN\n198897        NaN\n198898        NaN\n198899        NaN\nName: Zipcode, Length: 198900, dtype: float64\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "6b7913189882ac2ffd1d682f92f400505230e71f"
      },
      "cell_type": "code",
      "source": "sf_permits['Zipcode'].isnull().sum()\n# 1716 out of the 198899 are missing, which says that those values just were not recorded",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 42,
          "data": {
            "text/plain": "1716"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "ea022b62-6419-47e7-973e-c3e707e2795f",
        "_uuid": "3f72f46f2464c7cd12f5eb2a752746ce1cd0b5a7"
      },
      "cell_type": "markdown",
      "source": "# Drop missing values\n___\n\nIf you're in a hurry or don't have a reason to figure out why your values are missing, one option you have is to just remove any rows or columns that contain missing values. (Note: I don't generally recommend this approch for important projects! It's usually worth it to take the time to go through your data and really look at all the columns with missing values one-by-one to really get to know your dataset.)  \n\nIf you're sure you want to drop rows with missing values, pandas does have a handy function, `dropna()` to help you do this. Let's try it out on our NFL dataset!"
    },
    {
      "metadata": {
        "_cell_guid": "ad0ac9a2-2854-4bb7-8886-8eee7fad8756",
        "_uuid": "ad8ef7825ba9bce3472a47d7c5242a4522f14065",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# remove all the rows that contain a missing value\nnfl_data.dropna()",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 43,
          "data": {
            "text/plain": "Empty DataFrame\nColumns: [Date, GameID, Drive, qtr, down, time, TimeUnder, TimeSecs, PlayTimeDiff, SideofField, yrdln, yrdline100, ydstogo, ydsnet, GoalToGo, FirstDown, posteam, DefensiveTeam, desc, PlayAttempted, Yards.Gained, sp, Touchdown, ExPointResult, TwoPointConv, DefTwoPoint, Safety, Onsidekick, PuntResult, PlayType, Passer, Passer_ID, PassAttempt, PassOutcome, PassLength, AirYards, YardsAfterCatch, QBHit, PassLocation, InterceptionThrown, Interceptor, Rusher, Rusher_ID, RushAttempt, RunLocation, RunGap, Receiver, Receiver_ID, Reception, ReturnResult, Returner, BlockingPlayer, Tackler1, Tackler2, FieldGoalResult, FieldGoalDistance, Fumble, RecFumbTeam, RecFumbPlayer, Sack, Challenge.Replay, ChalReplayResult, Accepted.Penalty, PenalizedTeam, PenaltyType, PenalizedPlayer, Penalty.Yards, PosTeamScore, DefTeamScore, ScoreDiff, AbsScoreDiff, HomeTeam, AwayTeam, Timeout_Indicator, Timeout_Team, posteam_timeouts_pre, HomeTimeouts_Remaining_Pre, AwayTimeouts_Remaining_Pre, HomeTimeouts_Remaining_Post, AwayTimeouts_Remaining_Post, No_Score_Prob, Opp_Field_Goal_Prob, Opp_Safety_Prob, Opp_Touchdown_Prob, Field_Goal_Prob, Safety_Prob, Touchdown_Prob, ExPoint_Prob, TwoPoint_Prob, ExpPts, EPA, airEPA, yacEPA, Home_WP_pre, Away_WP_pre, Home_WP_post, Away_WP_post, Win_Prob, WPA, airWPA, ...]\nIndex: []\n\n[0 rows x 102 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>GameID</th>\n      <th>Drive</th>\n      <th>qtr</th>\n      <th>down</th>\n      <th>time</th>\n      <th>TimeUnder</th>\n      <th>TimeSecs</th>\n      <th>PlayTimeDiff</th>\n      <th>SideofField</th>\n      <th>...</th>\n      <th>yacEPA</th>\n      <th>Home_WP_pre</th>\n      <th>Away_WP_pre</th>\n      <th>Home_WP_post</th>\n      <th>Away_WP_post</th>\n      <th>Win_Prob</th>\n      <th>WPA</th>\n      <th>airWPA</th>\n      <th>yacWPA</th>\n      <th>Season</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows Ã— 102 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "e0545655-3d37-448b-ae56-2c7707cd805d",
        "_uuid": "33eb849e076d2a4d0c409f58d78b5f303879b1b3"
      },
      "cell_type": "markdown",
      "source": "Oh dear, it looks like that's removed all our data! ðŸ˜± This is because every row in our dataset had at least one missing value. We might have better luck removing all the *columns* that have at least one missing value instead."
    },
    {
      "metadata": {
        "_cell_guid": "97709ad4-f7b8-4cd0-8911-56e14db904ae",
        "_uuid": "87c569672854fe23e1ee9376ef3115ba4712cbf5",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# remove all columns with at least one missing value\ncolumns_with_na_dropped = nfl_data.dropna(axis=1)\ncolumns_with_na_dropped.head()",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 44,
          "data": {
            "text/plain": "         Date      GameID  Drive  qtr  TimeUnder  ydstogo  ydsnet  \\\n0  2009-09-10  2009091000      1    1         15        0       0   \n1  2009-09-10  2009091000      1    1         15       10       5   \n2  2009-09-10  2009091000      1    1         15        5       2   \n3  2009-09-10  2009091000      1    1         14        8       2   \n4  2009-09-10  2009091000      1    1         14        8       2   \n\n   PlayAttempted  Yards.Gained  sp   ...    Timeout_Indicator  Timeout_Team  \\\n0              1            39   0   ...                    0          None   \n1              1             5   0   ...                    0          None   \n2              1            -3   0   ...                    0          None   \n3              1             0   0   ...                    0          None   \n4              1             0   0   ...                    0          None   \n\n   posteam_timeouts_pre HomeTimeouts_Remaining_Pre AwayTimeouts_Remaining_Pre  \\\n0                     3                          3                          3   \n1                     3                          3                          3   \n2                     3                          3                          3   \n3                     3                          3                          3   \n4                     3                          3                          3   \n\n   HomeTimeouts_Remaining_Post  AwayTimeouts_Remaining_Post  ExPoint_Prob  \\\n0                            3                            3           0.0   \n1                            3                            3           0.0   \n2                            3                            3           0.0   \n3                            3                            3           0.0   \n4                            3                            3           0.0   \n\n   TwoPoint_Prob  Season  \n0            0.0    2009  \n1            0.0    2009  \n2            0.0    2009  \n3            0.0    2009  \n4            0.0    2009  \n\n[5 rows x 41 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>GameID</th>\n      <th>Drive</th>\n      <th>qtr</th>\n      <th>TimeUnder</th>\n      <th>ydstogo</th>\n      <th>ydsnet</th>\n      <th>PlayAttempted</th>\n      <th>Yards.Gained</th>\n      <th>sp</th>\n      <th>...</th>\n      <th>Timeout_Indicator</th>\n      <th>Timeout_Team</th>\n      <th>posteam_timeouts_pre</th>\n      <th>HomeTimeouts_Remaining_Pre</th>\n      <th>AwayTimeouts_Remaining_Pre</th>\n      <th>HomeTimeouts_Remaining_Post</th>\n      <th>AwayTimeouts_Remaining_Post</th>\n      <th>ExPoint_Prob</th>\n      <th>TwoPoint_Prob</th>\n      <th>Season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2009-09-10</td>\n      <td>2009091000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>15</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>39</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>None</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2009-09-10</td>\n      <td>2009091000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>15</td>\n      <td>10</td>\n      <td>5</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>None</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2009-09-10</td>\n      <td>2009091000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>15</td>\n      <td>5</td>\n      <td>2</td>\n      <td>1</td>\n      <td>-3</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>None</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2009-09-10</td>\n      <td>2009091000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>14</td>\n      <td>8</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>None</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2009-09-10</td>\n      <td>2009091000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>14</td>\n      <td>8</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>None</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2009</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 41 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "0e51b19b-c44d-4487-8417-725d2b911739",
        "_uuid": "e60a092d2799851aa725eadf28b197022a6b127f",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# just how much data did we lose?\nprint(\"Columns in original dataset: %d \\n\" % nfl_data.shape[1])\nprint(\"Columns with na's dropped: %d\" % columns_with_na_dropped.shape[1])",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Columns in original dataset: 102 \n\nColumns with na's dropped: 41\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "f417c614-f77f-45eb-b16b-fdc0be936502",
        "_uuid": "bac84fee4ca849e54839c716c43dddfbb559954b"
      },
      "cell_type": "markdown",
      "source": "We've lost quite a bit of data, but at this point we have successfully removed all the `NaN`'s from our data. "
    },
    {
      "metadata": {
        "_cell_guid": "0fe94654-7dad-4e8d-bbbb-e65e2bb2f767",
        "_uuid": "8207912f74712835283f7e1b30dad0471ee2e1fc",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Your turn! Try removing all the rows from the sf_permits dataset that contain missing values. How many are left?\nsf_permits.dropna()",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 47,
          "data": {
            "text/plain": "Empty DataFrame\nColumns: [Permit Number, Permit Type, Permit Type Definition, Permit Creation Date, Block, Lot, Street Number, Street Number Suffix, Street Name, Street Suffix, Unit, Unit Suffix, Description, Current Status, Current Status Date, Filed Date, Issued Date, Completed Date, First Construction Document Date, Structural Notification, Number of Existing Stories, Number of Proposed Stories, Voluntary Soft-Story Retrofit, Fire Only Permit, Permit Expiration Date, Estimated Cost, Revised Cost, Existing Use, Existing Units, Proposed Use, Proposed Units, Plansets, TIDF Compliance, Existing Construction Type, Existing Construction Type Description, Proposed Construction Type, Proposed Construction Type Description, Site Permit, Supervisor District, Neighborhoods - Analysis Boundaries, Zipcode, Location, Record ID]\nIndex: []\n\n[0 rows x 43 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Permit Number</th>\n      <th>Permit Type</th>\n      <th>Permit Type Definition</th>\n      <th>Permit Creation Date</th>\n      <th>Block</th>\n      <th>Lot</th>\n      <th>Street Number</th>\n      <th>Street Number Suffix</th>\n      <th>Street Name</th>\n      <th>Street Suffix</th>\n      <th>...</th>\n      <th>Existing Construction Type</th>\n      <th>Existing Construction Type Description</th>\n      <th>Proposed Construction Type</th>\n      <th>Proposed Construction Type Description</th>\n      <th>Site Permit</th>\n      <th>Supervisor District</th>\n      <th>Neighborhoods - Analysis Boundaries</th>\n      <th>Zipcode</th>\n      <th>Location</th>\n      <th>Record ID</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows Ã— 43 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "7ec643e1-abba-4683-b794-a1924e657501",
        "_uuid": "f804c0448b18b6d411ddf8452d15abba8292fffa",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Now try removing all the columns with empty values. Now how much of your data is left?\nprint(\"Columns in original sf dataset: %d \\n\" % sf_permits.shape[1])\ncolumns_with_na_dropped_sf = sf_permits.dropna(axis=1)\nprint(\"Columns with na's dropped: %d\" % columns_with_na_dropped.shape[1])",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Columns in original sf dataset: 43 \n\nColumns with na's dropped: 41\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "1dbe153d-7b30-4ad8-80ad-a4c7fb53928e",
        "_uuid": "eb1ef8d47d9ebed77c3d21eca24708708ed4d45f"
      },
      "cell_type": "markdown",
      "source": "# Filling in missing values automatically\n_____\n\nAnother option is to try and fill in the missing values. For this next bit, I'm getting a small sub-section of the NFL data so that it will print well."
    },
    {
      "metadata": {
        "_cell_guid": "76fd83fb-a6d9-4c03-8c94-a111ee529881",
        "_uuid": "e0944282c73a63513d5345689ddd6a9da0fc8547",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# get a small subset of the NFL dataset\nsubset_nfl_data = nfl_data.loc[:, 'EPA':'Season'].head()\nsubset_nfl_data",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 49,
          "data": {
            "text/plain": "        EPA    airEPA    yacEPA  Home_WP_pre  Away_WP_pre  Home_WP_post  \\\n0  2.014474       NaN       NaN     0.485675     0.514325      0.546433   \n1  0.077907 -1.068169  1.146076     0.546433     0.453567      0.551088   \n2 -1.402760       NaN       NaN     0.551088     0.448912      0.510793   \n3 -1.712583  3.318841 -5.031425     0.510793     0.489207      0.461217   \n4  2.097796       NaN       NaN     0.461217     0.538783      0.558929   \n\n   Away_WP_post  Win_Prob       WPA    airWPA    yacWPA  Season  \n0      0.453567  0.485675  0.060758       NaN       NaN    2009  \n1      0.448912  0.546433  0.004655 -0.032244  0.036899    2009  \n2      0.489207  0.551088 -0.040295       NaN       NaN    2009  \n3      0.538783  0.510793 -0.049576  0.106663 -0.156239    2009  \n4      0.441071  0.461217  0.097712       NaN       NaN    2009  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EPA</th>\n      <th>airEPA</th>\n      <th>yacEPA</th>\n      <th>Home_WP_pre</th>\n      <th>Away_WP_pre</th>\n      <th>Home_WP_post</th>\n      <th>Away_WP_post</th>\n      <th>Win_Prob</th>\n      <th>WPA</th>\n      <th>airWPA</th>\n      <th>yacWPA</th>\n      <th>Season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.014474</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.485675</td>\n      <td>0.514325</td>\n      <td>0.546433</td>\n      <td>0.453567</td>\n      <td>0.485675</td>\n      <td>0.060758</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.077907</td>\n      <td>-1.068169</td>\n      <td>1.146076</td>\n      <td>0.546433</td>\n      <td>0.453567</td>\n      <td>0.551088</td>\n      <td>0.448912</td>\n      <td>0.546433</td>\n      <td>0.004655</td>\n      <td>-0.032244</td>\n      <td>0.036899</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.402760</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.551088</td>\n      <td>0.448912</td>\n      <td>0.510793</td>\n      <td>0.489207</td>\n      <td>0.551088</td>\n      <td>-0.040295</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.712583</td>\n      <td>3.318841</td>\n      <td>-5.031425</td>\n      <td>0.510793</td>\n      <td>0.489207</td>\n      <td>0.461217</td>\n      <td>0.538783</td>\n      <td>0.510793</td>\n      <td>-0.049576</td>\n      <td>0.106663</td>\n      <td>-0.156239</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.097796</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.461217</td>\n      <td>0.538783</td>\n      <td>0.558929</td>\n      <td>0.441071</td>\n      <td>0.461217</td>\n      <td>0.097712</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2009</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "527c8703-4b29-459d-af7d-5505da36016b",
        "_uuid": "f8cfe916904af3265d8ecc4f791f9f62e34ff458"
      },
      "cell_type": "markdown",
      "source": "We can use the Panda's fillna() function to fill in missing values in a dataframe for us. One option we have is to specify what we want the `NaN` values to be replaced with. Here, I'm saying that I would like to replace all the `NaN` values with 0."
    },
    {
      "metadata": {
        "_cell_guid": "c01ed989-8901-43c8-afa3-6ca36605dfb5",
        "_uuid": "77eac530ce398b8c13eb7886f86bce48fd997f34",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# replace all NA's with 0\nsubset_nfl_data.fillna(0)",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 50,
          "data": {
            "text/plain": "        EPA    airEPA    yacEPA  Home_WP_pre  Away_WP_pre  Home_WP_post  \\\n0  2.014474  0.000000  0.000000     0.485675     0.514325      0.546433   \n1  0.077907 -1.068169  1.146076     0.546433     0.453567      0.551088   \n2 -1.402760  0.000000  0.000000     0.551088     0.448912      0.510793   \n3 -1.712583  3.318841 -5.031425     0.510793     0.489207      0.461217   \n4  2.097796  0.000000  0.000000     0.461217     0.538783      0.558929   \n\n   Away_WP_post  Win_Prob       WPA    airWPA    yacWPA  Season  \n0      0.453567  0.485675  0.060758  0.000000  0.000000    2009  \n1      0.448912  0.546433  0.004655 -0.032244  0.036899    2009  \n2      0.489207  0.551088 -0.040295  0.000000  0.000000    2009  \n3      0.538783  0.510793 -0.049576  0.106663 -0.156239    2009  \n4      0.441071  0.461217  0.097712  0.000000  0.000000    2009  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EPA</th>\n      <th>airEPA</th>\n      <th>yacEPA</th>\n      <th>Home_WP_pre</th>\n      <th>Away_WP_pre</th>\n      <th>Home_WP_post</th>\n      <th>Away_WP_post</th>\n      <th>Win_Prob</th>\n      <th>WPA</th>\n      <th>airWPA</th>\n      <th>yacWPA</th>\n      <th>Season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.014474</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.485675</td>\n      <td>0.514325</td>\n      <td>0.546433</td>\n      <td>0.453567</td>\n      <td>0.485675</td>\n      <td>0.060758</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.077907</td>\n      <td>-1.068169</td>\n      <td>1.146076</td>\n      <td>0.546433</td>\n      <td>0.453567</td>\n      <td>0.551088</td>\n      <td>0.448912</td>\n      <td>0.546433</td>\n      <td>0.004655</td>\n      <td>-0.032244</td>\n      <td>0.036899</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.402760</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.551088</td>\n      <td>0.448912</td>\n      <td>0.510793</td>\n      <td>0.489207</td>\n      <td>0.551088</td>\n      <td>-0.040295</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.712583</td>\n      <td>3.318841</td>\n      <td>-5.031425</td>\n      <td>0.510793</td>\n      <td>0.489207</td>\n      <td>0.461217</td>\n      <td>0.538783</td>\n      <td>0.510793</td>\n      <td>-0.049576</td>\n      <td>0.106663</td>\n      <td>-0.156239</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.097796</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.461217</td>\n      <td>0.538783</td>\n      <td>0.558929</td>\n      <td>0.441071</td>\n      <td>0.461217</td>\n      <td>0.097712</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2009</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "1103b725-c823-4f40-9bda-e97997856339",
        "_uuid": "bec603202c6bfaae7a49b4a4042f37019ad1d801"
      },
      "cell_type": "markdown",
      "source": "I could also be a bit more savvy and replace missing values with whatever value comes directly after it in the same column. (This makes a lot of sense for datasets where the observations have some sort of logical order to them.)"
    },
    {
      "metadata": {
        "_cell_guid": "90ddac9b-ee20-492e-b437-0519c97ca317",
        "_uuid": "afba99aa7897539e9a0af77dce03daab94d0ca68",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# replace all NA's the value that comes directly after it in the same column, \n# then replace all the reamining na's with 0\nsubset_nfl_data.fillna(method = 'bfill', axis=0).fillna(0)",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 51,
          "data": {
            "text/plain": "        EPA    airEPA    yacEPA  Home_WP_pre  Away_WP_pre  Home_WP_post  \\\n0  2.014474 -1.068169  1.146076     0.485675     0.514325      0.546433   \n1  0.077907 -1.068169  1.146076     0.546433     0.453567      0.551088   \n2 -1.402760  3.318841 -5.031425     0.551088     0.448912      0.510793   \n3 -1.712583  3.318841 -5.031425     0.510793     0.489207      0.461217   \n4  2.097796  0.000000  0.000000     0.461217     0.538783      0.558929   \n\n   Away_WP_post  Win_Prob       WPA    airWPA    yacWPA  Season  \n0      0.453567  0.485675  0.060758 -0.032244  0.036899    2009  \n1      0.448912  0.546433  0.004655 -0.032244  0.036899    2009  \n2      0.489207  0.551088 -0.040295  0.106663 -0.156239    2009  \n3      0.538783  0.510793 -0.049576  0.106663 -0.156239    2009  \n4      0.441071  0.461217  0.097712  0.000000  0.000000    2009  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EPA</th>\n      <th>airEPA</th>\n      <th>yacEPA</th>\n      <th>Home_WP_pre</th>\n      <th>Away_WP_pre</th>\n      <th>Home_WP_post</th>\n      <th>Away_WP_post</th>\n      <th>Win_Prob</th>\n      <th>WPA</th>\n      <th>airWPA</th>\n      <th>yacWPA</th>\n      <th>Season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.014474</td>\n      <td>-1.068169</td>\n      <td>1.146076</td>\n      <td>0.485675</td>\n      <td>0.514325</td>\n      <td>0.546433</td>\n      <td>0.453567</td>\n      <td>0.485675</td>\n      <td>0.060758</td>\n      <td>-0.032244</td>\n      <td>0.036899</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.077907</td>\n      <td>-1.068169</td>\n      <td>1.146076</td>\n      <td>0.546433</td>\n      <td>0.453567</td>\n      <td>0.551088</td>\n      <td>0.448912</td>\n      <td>0.546433</td>\n      <td>0.004655</td>\n      <td>-0.032244</td>\n      <td>0.036899</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.402760</td>\n      <td>3.318841</td>\n      <td>-5.031425</td>\n      <td>0.551088</td>\n      <td>0.448912</td>\n      <td>0.510793</td>\n      <td>0.489207</td>\n      <td>0.551088</td>\n      <td>-0.040295</td>\n      <td>0.106663</td>\n      <td>-0.156239</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.712583</td>\n      <td>3.318841</td>\n      <td>-5.031425</td>\n      <td>0.510793</td>\n      <td>0.489207</td>\n      <td>0.461217</td>\n      <td>0.538783</td>\n      <td>0.510793</td>\n      <td>-0.049576</td>\n      <td>0.106663</td>\n      <td>-0.156239</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.097796</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.461217</td>\n      <td>0.538783</td>\n      <td>0.558929</td>\n      <td>0.441071</td>\n      <td>0.461217</td>\n      <td>0.097712</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2009</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "980e5d67-7e9c-41a3-b17e-51d87e9da9cf",
        "_uuid": "1f8ac8b52f2933612e315f06a53185e164e6c5bc"
      },
      "cell_type": "markdown",
      "source": "Filling in missing values is also known as \"imputation\", and you can find more exercises on it [in this lesson, also linked under the \"More practice!\" section](https://www.kaggle.com/dansbecker/handling-missing-values). First, however, why don't you try replacing some of the missing values in the sf_permit dataset?"
    },
    {
      "metadata": {
        "_cell_guid": "da426397-7e17-40ce-a0d4-ca6d39e47498",
        "_uuid": "f7d403c19eaf31ee0a4e04b9e1119eda96a9f95c",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Your turn! Try replacing all the NaN's in the sf_permits data with the one that\n# comes directly after it and then replacing any remaining NaN's with 0\nmissing_values_count_sf",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 54,
          "data": {
            "text/plain": "Permit Number                                  0\nPermit Type                                    0\nPermit Type Definition                         0\nPermit Creation Date                           0\nBlock                                          0\nLot                                            0\nStreet Number                                  0\nStreet Number Suffix                      196684\nStreet Name                                    0\nStreet Suffix                               2768\nUnit                                      169421\nUnit Suffix                               196939\nDescription                                  290\nCurrent Status                                 0\nCurrent Status Date                            0\nFiled Date                                     0\nIssued Date                                14940\nCompleted Date                            101709\nFirst Construction Document Date           14946\nStructural Notification                   191978\nNumber of Existing Stories                 42784\nNumber of Proposed Stories                 42868\nVoluntary Soft-Story Retrofit             198865\nFire Only Permit                          180073\nPermit Expiration Date                     51880\nEstimated Cost                             38066\nRevised Cost                                6066\nExisting Use                               41114\nExisting Units                             51538\nProposed Use                               42439\nProposed Units                             50911\nPlansets                                   37309\nTIDF Compliance                           198898\nExisting Construction Type                 43366\nExisting Construction Type Description     43366\nProposed Construction Type                 43162\nProposed Construction Type Description     43162\nSite Permit                               193541\nSupervisor District                         1717\nNeighborhoods - Analysis Boundaries         1725\nZipcode                                     1716\nLocation                                    1700\nRecord ID                                      0\ndtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "583b9fd327d4eb1a43b5190a6ab64498e853778b"
      },
      "cell_type": "code",
      "source": "subset_sf_data = sf_permits.loc[:, 'Street Number Suffix': 'Unit'].head()\nsubset_sf_data",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 64,
          "data": {
            "text/plain": "  Street Number Suffix Street Name Street Suffix  Unit\n0                  NaN       Ellis            St   NaN\n1                  NaN       Geary            St   0.0\n2                  NaN     Pacific            Av   NaN\n3                  NaN     Pacific            Av   0.0\n4                  NaN      Market            St   NaN",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Street Number Suffix</th>\n      <th>Street Name</th>\n      <th>Street Suffix</th>\n      <th>Unit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>Ellis</td>\n      <td>St</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>Geary</td>\n      <td>St</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>Pacific</td>\n      <td>Av</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>Pacific</td>\n      <td>Av</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>Market</td>\n      <td>St</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "10ab9f5705e9352d75a0f73728a887997a2e5e74"
      },
      "cell_type": "code",
      "source": "subset_sf_data.fillna(method = 'bfill', axis=0).fillna(0)",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 71,
          "data": {
            "text/plain": "   Street Number Suffix Street Name Street Suffix  Unit\n0                   0.0       Ellis            St   0.0\n1                   0.0       Geary            St   0.0\n2                   0.0     Pacific            Av   0.0\n3                   0.0     Pacific            Av   0.0\n4                   0.0      Market            St   0.0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Street Number Suffix</th>\n      <th>Street Name</th>\n      <th>Street Suffix</th>\n      <th>Unit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>Ellis</td>\n      <td>St</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>Geary</td>\n      <td>St</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>Pacific</td>\n      <td>Av</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>Pacific</td>\n      <td>Av</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>Market</td>\n      <td>St</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a565b25043548bc1ee35bd7b77aad8ccca64a6f9"
      },
      "cell_type": "code",
      "source": "sf_permits['Zipcode']",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 72,
          "data": {
            "text/plain": "0         94102.0\n1         94102.0\n2         94109.0\n3         94109.0\n4         94102.0\n5         94107.0\n6         94122.0\n7         94124.0\n8         94117.0\n9         94117.0\n10        94114.0\n11        94102.0\n12        94114.0\n13        94131.0\n14        94115.0\n15        94108.0\n16        94104.0\n17        94114.0\n18        94123.0\n19        94114.0\n20        94117.0\n21        94110.0\n22        94133.0\n23        94123.0\n24        94123.0\n25        94122.0\n26        94121.0\n27        94117.0\n28        94122.0\n29        94102.0\n           ...   \n198870    94109.0\n198871    94117.0\n198872    94114.0\n198873    94110.0\n198874    94131.0\n198875    94102.0\n198876    94117.0\n198877    94112.0\n198878    94110.0\n198879    94112.0\n198880    94122.0\n198881    94133.0\n198882    94112.0\n198883    94102.0\n198884    94103.0\n198885    94116.0\n198886        NaN\n198887        NaN\n198888        NaN\n198889        NaN\n198890        NaN\n198891        NaN\n198892        NaN\n198893        NaN\n198894        NaN\n198895        NaN\n198896        NaN\n198897        NaN\n198898        NaN\n198899        NaN\nName: Zipcode, Length: 198900, dtype: float64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "b4f37fce-4d08-409e-bbbd-6a26c3bbc6ee",
        "_uuid": "52b0af56e3c77db96056e9acd785f8f435f7caf5"
      },
      "cell_type": "markdown",
      "source": "And that's it for today! If you have any questions, be sure to post them in the comments below or [on the forums](https://www.kaggle.com/questions-and-answers). \n\nRemember that your notebook is private by default, and in order to share it with other people or ask for help with it, you'll need to make it public. First, you'll need to save a version of your notebook that shows your current work by hitting the \"Commit & Run\" button. (Your work is saved automatically, but versioning your work lets you go back and look at what it was like at the point you saved it. It also let's you share a nice compiled notebook instead of just the raw code.) Then, once your notebook is finished running, you can go to the Settings tab in the panel to the left (you may have to expand it by hitting the [<] button next to the \"Commit & Run\" button) and setting the \"Visibility\" dropdown to \"Public\".\n\n# More practice!\n___\n\nIf you're looking for more practice handling missing values, check out these extra-credit\\* exercises:\n\n* [Handling Missing Values](https://www.kaggle.com/dansbecker/handling-missing-values): In this notebook Dan shows you several approaches to imputing missing data using scikit-learn's imputer. \n* Look back at the `Zipcode` column in the `sf_permits` dataset, which has some missing values. How would you go about figuring out what the actual zipcode of each address should be? (You might try using another dataset. You can search for datasets about San Fransisco on the [Datasets listing](https://www.kaggle.com/datasets).) \n\n\\* no actual credit is given for completing the challenge, you just learn how to clean data real good :P"
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}